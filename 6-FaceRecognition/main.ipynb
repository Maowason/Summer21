{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 1 - captures the photo of user\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        frame = cv2.flip(frame,1)\n",
    "        \n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (300, 300))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './azureaifaces/faces/IMG_TEST_' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 9: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "\n",
    "#!pip install azure-cognitiveservices-vision-customvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n",
    "\n",
    "project_id = '36ec88e3-0b08-4c99-ab6f-0be8803f2ec9'\n",
    "cv_key = 'f00a596c2ab748a3a0fc81364492ac0b'\n",
    "cv_endpoint = 'https://facerectask6-prediction.cognitiveservices.azure.com/'\n",
    "\n",
    "model_name = 'model1' # this must match the model name you set when publishing your model iteration (it's case-sensitive)!\n",
    "print('Ready to predict using model {} in project {}'.format(model_name, project_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\n",
    "\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Get the test images from the data/vision/test folder\n",
    "test_folder = os.path.join('azureaifaces','faces')\n",
    "test_images = os.listdir(test_folder)\n",
    "\n",
    "# Create an instance of the prediction service\n",
    "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": cv_key})\n",
    "custom_vision_client = CustomVisionPredictionClient(endpoint=cv_endpoint, credentials=credentials)\n",
    "\n",
    "# Create a figure to display the results\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Get the images and show the predicted classes for each one\n",
    "print('Classifying images in {} ...'.format(test_folder))\n",
    "arr = []\n",
    "for i in range(len(test_images)):\n",
    "    # Open the image, and use the custom vision model to classify it\n",
    "    image_contents = open(os.path.join(test_folder, test_images[i]), \"rb\")\n",
    "    classification = custom_vision_client.classify_image(project_id, model_name, image_contents.read())\n",
    "    # The results include a prediction for each tag, in descending order of probability - get the first one\n",
    "    prediction = classification.predictions[0].tag_name\n",
    "    arr.append(prediction)\n",
    "    # Display the image with its predicted class\n",
    "    img = Image.open(os.path.join(test_folder, test_images[i]))\n",
    "    a=fig.add_subplot(len(test_images)/3, 3,i+1)\n",
    "    a.axis('off')\n",
    "    imgplot = plt.imshow(img)\n",
    "    a.set_title(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#Condition to send mail and whatsapp message\n",
    "#############################################\n",
    "   \n",
    "if max(arr,key=arr.count)==\"haha\":\n",
    "    import os\n",
    "    import smtplib\n",
    "    from email.mime.text import MIMEText\n",
    "    from email.mime.image import MIMEImage\n",
    "    from email.mime.multipart import MIMEMultipart\n",
    "    import smtplib\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    MY_EMAIL=os.getenv('MY_EMAIL')\n",
    "    MY_PASSWORD = os.getenv('MY_PASSWORD')\n",
    "\n",
    "\n",
    "    def SendMail(ImgFileName):\n",
    "        with open(ImgFileName, 'rb') as f:\n",
    "            img_data = f.read()\n",
    "\n",
    "        msg = MIMEMultipart()\n",
    "        msg['Subject'] = 'Madhhav Spotted'\n",
    "        msg['From'] = 'sender@gmail.com'\n",
    "        msg['To'] = 'receiver@gmail.com'\n",
    "\n",
    "        text = MIMEText(\"Madhhav Was Spotted\")\n",
    "        msg.attach(text)\n",
    "        image = MIMEImage(img_data, name=os.path.basename(ImgFileName))\n",
    "        msg.attach(image)\n",
    "\n",
    "        s = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        s.ehlo()\n",
    "        s.starttls()\n",
    "        s.ehlo()\n",
    "        s.login(MY_EMAIL, MY_PASSWORD)\n",
    "        s.sendmail('sender@gmail.com', 'receiver@gmail.com', msg.as_string())\n",
    "        s.quit()\n",
    "        print(\"Mail Sent\")\n",
    "    SendMail('azureaifaces/faces/IMG_TEST_1.jpg')\n",
    "#############################################\n",
    "#Condition to create instance and attach ebs\n",
    "#############################################\n",
    "    \n",
    "elif max(arr,key=arr.count)==\"madhhav\":\n",
    "    import boto3\n",
    "    import time\n",
    "    ec2 = boto3.resource('ec2')\n",
    "    ec2_client = boto3.client('ec2')\n",
    "    # create a new EC2 instance\n",
    "    instances = ec2.create_instances(\n",
    "        ImageId='ami-00b6a8a2bd28daf19',\n",
    "        MinCount=1,\n",
    "        Placement={\n",
    "           'AvailabilityZone':'ap-south-1a'\n",
    "        },\n",
    "        MaxCount=1,\n",
    "        InstanceType='t2.micro'\n",
    "    )\n",
    "    print(\"Instance Created\")\n",
    "    id1 = str(instances[0])\n",
    "    id1 = id1[17:-2]\n",
    "    # create an EBS volume, 20G size\n",
    "    print(\"Creating EBS\")\n",
    "    ebs_vol = ec2.create_volume(\n",
    "        Size=5,\n",
    "        AvailabilityZone='ap-south-1a'\n",
    "    )\n",
    "    print(\"EBS Created!\")\n",
    "    time.sleep(30)\n",
    "    id2 = str(ebs_vol)\n",
    "    id2 = id2[15:-2]\n",
    "\n",
    "    response= ec2_client.attach_volume(\n",
    "            Device=\"/dev/xvdb\",\n",
    "            InstanceId=id1,\n",
    "            VolumeId=id2\n",
    "        )\n",
    "    print(\"Volume Attached to EC2 Instance!\")\n",
    "\n",
    "    if response['ResponseMetadata']['HTTPStatusCode']== 200:\n",
    "        ec2_client.get_waiter('volume_in_use').wait(\n",
    "            VolumeIds=[id2],\n",
    "            DryRun=False\n",
    "        )\n",
    "    print(\"FINALLY DONEE!\")\n",
    "    \n",
    "elif max(arr,key=arr.count)==\"avanish\":\n",
    "    import pywhatkit as kit    \n",
    "    print(\"******************************************Sending Whatsapp Message***********************************\")\n",
    "    kit.sendwhatmsg_instantly(phone_no=\"+911234567899\", message=\"Hey Face Recognised !!\\n\")\n",
    "else:\n",
    "    print(\"Haha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
